# Storage policies

> ðŸ’¡ Instructions about how to use this project can be found [here](../README.md).

ClickHouse (and any other database) gets its speed from two things, mainly: **a)** speed to get data (compression, underlaying hardware, files structure, etc.) and **b)** how to process it (vectorised execution - also called SIMD, ad-hoc algorithms, etc.). This allows ClickHouse to work with massive amounts of data but this raises another challenge: data storage is limited and, usually, all maintenance operations related to storage are tedious and dangerous.

You could exploit TTLs to automatically delete expired data, both at table and column level, you could also orchestrate backups of your data, both valid things but it's important to be aware of TTL based data movement between disks.

A common use case is to require fast reads for recent data and to be willing to accept slower reads for older data (which is read less frequently too).  
Given that **SSD/NVMe disks are more expensive than spinning disks, and the latter usually have more capacity**, you can imagine scenarios where either old data gets inserted into spinning disks or gets moved to it when they eventually become old.

In addition, instead of spinning disk, you can **save data into S3** (or compatible object storage services). This is the case we will explore today.

- [Storage policies](#storage-policies)
  - [Configuration](#configuration)
  - [S3 only](#s3-only)
  - [Tiered storage](#tiered-storage)
  - [Wrapping up](#wrapping-up)

Related docs:

https://clickhouse.tech/docs/en/engines/table-engines/mergetree-family/mergetree/#mergetree-table-ttl
https://clickhouse.tech/docs/en/engines/table-engines/mergetree-family/mergetree/#table_engine-mergetree-s3
https://clickhouse.tech/docs/en/operations/system-tables/storage_policies/
https://clickhouse.tech/docs/en/sql-reference/statements/alter/partition/#alter_move-partition
https://altinity.com/blog/clickhouse-and-s3-compatible-object-storage

## Configuration

ClickHouse [configuration file](docker/clickhouse/config.xml) contains a `Storage Configuration` section that looks like this:

```xml
<storage_configuration>
    <!-- S3 credentials -->
    <disks>
        <s3>
            <type>s3</type>
            <endpoint>http://minio:9000/clickhouse/data/</endpoint>
            <access_key_id>user</access_key_id>
            <secret_access_key>changeme</secret_access_key>
            <region></region>
        </s3>
    </disks>
    <policies>
        <default_to_s3>
            <volumes>
                <default>
                    <disk>default</disk>
                </default>
                <s3>
                    <disk>s3</disk>
                    <perform_ttl_move_on_insert>0</perform_ttl_move_on_insert>
                </s3>
            </volumes>
        </default_to_s3>
        <s3only>
            <volumes>
                <s3>
                    <disk>s3</disk>
                    <perform_ttl_move_on_insert>0</perform_ttl_move_on_insert>
                </s3>
            </volumes>
        </s3only>
    </policies>
</storage_configuration>
```

It consits of 2 parts, `disks` and `policies`.  
As you can see, there is only one disk defined named `s3` but, in reality, there's another one called `default` which, but not being defined, it keeps all its default configuration.

You can get information about the configured disks by running `SELECT * FROM system.disks;`

Since this project aims to be self-sufficient and self-contained we will use [minIO](https://min.io/), which is fully compatible with S3.

You will then find 2 policies: `default_to_s3` and `s3only`. As you can imagine, first allows you move data from default disk to s3 disk, while the second stores data only in s3.

`<perform_ttl_move_on_insert>0</perform_ttl_move_on_insert>` means that data will be inserted in `default` and then moved to `s3` as a background operation, which speeds up insert time.

To get information about the configured storage policies run `SELECT * FROM system.storage_policies`;.

## S3 only

Let's open a ClickHouse terminal and create our schema.

```sql
CREATE DATABASE IF NOT EXISTS storage;
```

```sql
USE storage;
```

```sql
CREATE TABLE IF NOT EXISTS s3 
(
    timestamp DateTime,
    uuid UUID
) 
ENGINE = MergeTree()
ORDER BY timestamp
SETTINGS storage_policy = 's3only';
```

The `SETTINGS storage_policy = 's3only'` part specifies that data will use the policy `s3only` which will store data only in S3 (MinIO, in our case).

Also have a look at the `UUID` data type, which is stored more efficiently than if its treated as a regular string.  
https://clickhouse.tech/docs/en/sql-reference/data-types/uuid/

And let's insert something:

```sql
INSERT into s3 VALUES(now(), generateUUIDv4());
```

Now [open MinIO's GUI](http://localhost:9123/minio/clickhouse/data/) and you'll see how data has been stored there.

And by doing

```sql
TRUNCATE TABLE s3 NO DELAY;
```

those objects will be deleted (at exception of a 1 byte file).

## Tiered storage

Let's now try a table that has part of its data in the default disk and the rest in S3.

```sql
CREATE TABLE IF NOT EXISTS tiered
(
    timestamp DateTime,
    uuid UUID
) 
ENGINE = MergeTree()
ORDER BY timestamp
TTL toStartOfMinute(timestamp) + interval 3 minute to volume 's3'
SETTINGS storage_policy = 'default_to_s3';
```

Our policy says that any row which timestamp start of minute is older than 3 minutes, will be **eventually** moved to s3.

```sql
INSERT INTO tiered 
SELECT
    now() - (rand() % 360),
    generateUUIDv4()
FROM numbers(6000);
```

Now, by opening [open MinIO's GUI](http://localhost:9123/minio/clickhouse/data/) you might not see anything yet since TTL based moved background job might not have started yet. After a while you will see data moved to s3.  
You can accelerate this by typing `SYSTEM START MOVES`;

## Wrapping up

Some housekeeping:

```sql
DROP DATABASE storage SYNC;
```

This operation will also delete the data in S3 that belonged to the tables in this database.
