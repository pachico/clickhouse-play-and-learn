# MergeTree Materialised Views with SummingMergeTree

> ğŸ’¡ Instructions about how to use this project can be found [here](../README.md).

https://clickhouse.tech/docs/en/sql-reference/statements/create/view/#materialized

We learned how `materialising` a column might have a performance boost at query time. Wouldn't it be great to do the same but at table level? This is precisely what `materialised views` solve.

The mechanics of materialised views are the following:

1. data is inserted into a source table (we will keep calling it `source` for the sake of understanding its purpose)
2. at insert time, it is evaluated by the materialised view' `SELECT` logic
3. and its result is inserted into another table

Now, as you might have understood, this doesn't itself provide any benefit since you could be just duplicating the raw data in another table.

> It is indeed a common pattern to replicate data in a table with a different indexing pattern.

The real benefit is to replicate the data in a table that can automatically perform aggregations at insert-time, providing, therefore, real time aggregation.

We will here explore the simplest of all the aggregating table engines, the `SummingMergeTree`.

- [MergeTree Materialised Views with SummingMergeTree](#mergetree-materialised-views-with-summingmergetree)
  - [Table creation](#table-creation)
  - [Inserting data](#inserting-data)
  - [Checking materialised data](#checking-materialised-data)
  - [Wrapping up](#wrapping-up)

## Table creation

```sql
CREATE DATABASE IF NOT EXISTS mergetree;
```

and use it (this means selecting it):

```sql
use mergetree;
```

and create the table we will insert data into:

```sql
CREATE TABLE IF NOT EXISTS source
(
    `number` UInt32
)
ENGINE = MergeTree
PARTITION BY tuple()
ORDER BY number;
```

Now we will create the table where the aggregate data will be stored and the logic that puts it there:

```sql
CREATE TABLE IF NOT EXISTS target
(
  parity LowCardinality(String),
  count UInt32
) 
ENGINE =  SummingMergeTree()
ORDER BY parity;
```

Let's dissec a new concept introduced here:

`LowCardinality(String)` makes a dictionary (sort of hash table) out of this column. In previous examples we used an `Enum` type, which is more efficient but for which you need to know all its possible values upfront. If this is not the case but you still know that the cardinality is low, it's a great choice.

Getting back to `SummingMergeTree`, as specified in the documentation:

> The difference is that when merging data parts for SummingMergeTree tables ClickHouse replaces all the rows with the same primary key (or more accurately, with the same sorting key) with one row which contains summarized values for the columns with the numeric data type.

This means that all columns not specified in the ORDER clause (parity is, so it applies to count) will be aggregated.

```sql
CREATE MATERIALIZED VIEW IF NOT EXISTS target_view TO target AS
SELECT
    IF(modulo(number, 2) = 0, 'even', 'odd') as parity,
    1 as count
FROM source;
```

At this point, when doing `show tables` you should see 3 elements:

```txt
SHOW TABLES

Query id: e61ab382-db39-483b-8cb2-75932a357144

â”Œâ”€nameâ”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ source      â”‚
â”‚ target      â”‚
â”‚ target_view â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

3 rows in set. Elapsed: 0.002 sec. 
```

## Inserting data

```sql
INSERT INTO source
SELECT 
    number
FROM numbers(10000000);
```

## Checking materialised data

Let's see the results of our work. If I were to count by parity in the source table we would do:

```sql
SELECT
    IF((number % 2) = 0, 'even', 'odd') AS parity,
    count() AS count
FROM source
GROUP BY parity

Query id: eb23e003-be57-4496-9fe9-d5359773d899

â”Œâ”€parityâ”€â”¬â”€â”€â”€countâ”€â”
â”‚ odd    â”‚ 5000000 â”‚
â”‚ even   â”‚ 5000000 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

2 rows in set. Elapsed: 0.123 sec. Processed 10.00 million rows, 40.00 MB (81.57 million rows/s., 326.27 MB/s.) 

```

And if we wanted to use our materialised view/table we'd use the following:

```sql
SELECT
    parity,
    sum(count)
FROM target
GROUP BY parity

Query id: 9415721e-e412-49c5-bf8c-07abd581d3b9

â”Œâ”€parityâ”€â”¬â”€sum(count)â”€â”
â”‚ even   â”‚    5000000 â”‚
â”‚ odd    â”‚    5000000 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

2 rows in set. Elapsed: 0.002 sec. 

```

You might be wondering why do we have group by parity. Wasn't perhaps the whole purpose of the SummingMergeTree to automatically aggregate? Yes, but this is another background operation so you have to consider certain "parts" might not be merged/aggregated yet.

In any case, let's look again at the latencies: `0.123 sec` vs `0.002 sec`. We got an enormous boost again!

## Wrapping up

We will learn more advanced aggregation engines and techniches but for now imagine the amount of simple use cases you can solve with this technique!

Now, do some housekeeping:

```sql
DROP TABLE source SYNC;
DROP TABLE target SYNC;
DROP TABLE target_view SYNC;
```

Wait, wait, what is this new `SYNC` at the end of the drop statement? As you well imagined, `DROP TABLE` is also an operation that is completed asynchronously.  
If you want to complete it synchronously, then append the `SYNC` keyword at the end.

Why should you bother? In replicated tables that use `Zookeeper` (we'll get to this) or other storage types like `S3` (we'll get to this too), it might be important to finish the drop operation if you want to quickly recreate a table with the same name (or Zookeeper or disk path).
Don't worry, just remember that most operations are asynchronous and you, therefore, need to either make then synchronous or assume they will happen in the background (recommended approach).
